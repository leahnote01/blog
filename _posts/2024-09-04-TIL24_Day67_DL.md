---
title: "Day67 Deep Learning Lecture Review - Lecture 2 (1)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [dlReview, neuralNetwork, TIL_24]
toc: true 
---

# Lecture 2: Paradigms Beyond Supervised Learning and Neural Network

<img src="/blog/images/2024-09-04-TIL24_Day67_DL/E078B106-915B-47B6-B14F-816FCBFA5E13.jpeg"><br><br>



## 1. Paradigms Beyond Supervised Learning

### Types of Learning

- Supervised Learning
  - Training data includes desired output.
  - classification & regression



- Unsupervised Learning
  - Training data does not include the desired output.
  - clustering, dimensionality reduction, density estimation



- Self-Supervised Learning
  - Training data labels itself somehow.



- Reinforced Learning
  - A type of machine learning where an agent <u>learns to behave in an environment by performing actions and seeing the results, often as rewards or punishments</u>
  - In supervised learning, a function approximation such as 'f(x)=y' is given to the model, but in RL, within the environment, the agent can take actions at each time step, and <u>it is not told exactly what to do.</u>
  - The model gets a scaler reward signal.
    - ex) Won the game $\rightarrow$ +1, or lost the game -1
  - Wants to maximize the reward
  - Examples
    - Gaming:
      - AlphaGo: The program developed by DeepMind that learns to play the board game Go and can compete against top human players.
      - Video Game Play: Agents developed to play and master complex video games like those from the Atari game suite.
    - Robotics:
      - Autonomous Vehicles: Developing driving policies for autonomous cars that can navigate complex traffic scenarios.
      - Robotic Manipulation: Robots learning to manipulate objects through trial and error, improving their ability to perform tasks such as assembly-line work or surgical operations.

<br>

## 2. A Variety of Neural Network

> We will reivew a high-level neural network architectures, which are <u> all based on the MLP.</u> The goal is to get to know deeper with the Inputs and Outputs of each of the number of nerural network systems. 



### Fully Connected Networks (MLPs)

- Cannot do  $\rightarrow$ <u>Extend to handle other forms</u>
  - efficently handle images and videos $\rightarrow$ Convolutional Neural Networks
  - sequntial inputs and sets (text, audio, etc.) $\rightarrow$ RNNs, Transformers
  - exotic data structures, (e.g.m graphs as input) $\rightarrow$ Graph Neural Networks

- Each kind of neural network arcitecture has layers that have particular properties
  - Can mix and match them
- Ofthen MLP layers are used near the top of many network architectures to facilitate classification / regression

<br>

### Inductive Bias

- Inductive Bias: <u>Assumptions built into the learning algorithm</u>
- Crucial in shaping how models learn and generalize. The architecture and configuration of a deep neural network itself introduces specific biases that affect the learning outcomes.
  - Using convlutions is an inductive bias, since they assume the same filter is useful across the entire image
- MLPs lack a strong inductive bias in the architecture
  - Can include some weak form in some losses or regularizers

<br>

### Convolutional Neural Networks

- Definition
  - A form of neural network that <u>has an inductive bias</u>
    - Use convolutional units (spatially tied weights) implemented via linear filtering

- A deep learning neural network architecture <u>that learns directly from data</u>. CNNs are particularly useful for finding patterns in images for object, class, and category recognition.



- Fully Connected MLP network vs. Convolutional Neural Network

  <center>
    <img src="/blog/images/2024-09-04-TIL24_Day67_DL/image-20240905193316994.png" width="80%"><br>
    <Font size= 3pt><I>Perceptron(Image from: https://www.simplilearn.com/tutorials/deep-learning-tutorial/multilayer-perceptron#:~:text=A%20fully%20connected%20multi%2Dlayer,a%20feedforward%20artificial%20neural%20network)</I></Font><br><br>
  </center>

  - Perceptron
    - Perceptron rule and Adaline rule were used to train a single-layer neural network
    - <u>Weights are updated based on a unit function in perceptron rule</u> or on a linear function in Adaline Rule.

  <center>
    <img src="/blog/images/2024-09-04-TIL24_Day67_DL/image-20240905193807751.png" width="80%"><br>
    <Font size= 3pt><I>Multi-Layered ANN(Image from: https://www.simplilearn.com/tutorials/deep-learning-tutorial/multilayer-perceptron#:~:text=A%20fully%20connected%20multi%2Dlayer,a%20feedforward%20artificial%20neural%20network)</I></Font> <br><br>
  </center>

  - Multi-Layer Perceptron

    - <u>A fully connected multi-layer neural network</u> is called a Multilayer Perceptron (MLP).

    - It has 3 layers including one hidden layer. If it has more than 1 hidden layer, it is called a deep ANN. An MLP is a typical example of a feedforward artificial neural network.

    - To optimize a neural network, it's important to <u>adjust the number of layers and neurons</u>, which are referred to as **hyperparameters**. This process involves using cross-validation techniques to identify the most effective values for these parameters.

    - Weight adjustment training in neural networks involves **backpropagation**, a process in which the network adjusts the weights of its connections <u>to reduce errors.</u> Deeper neural networks can encounter <u>vanishing gradient problems</u>, where the gradient becomes extremely <u>small</u>, hindering the learning process. 

      | Feature         | MLP (Fully Connected) | CNN (Convolutional Neural Network)              |
      | --------------- | --------------------- | ----------------------------------------------- |
      | **Basic Unit**  | Neuron                | Convolutional Unit                              |
      | **Unit Input**  | Vector                | Tensor (3D for images: width, height, channels) |
      | **Unit Output** | 1 number (scalar)     | Feature Map (tensor)                            |

<br>

- How does Convolutional Network work?<br>
  ![image-20240905202317255](/images/2024-09-04-TIL24_Day67_DL/image-20240905202317255.png)



### Side Note: What is CNN?

![image-20240905202615347](/images/2024-09-04-TIL24_Day67_DL/image-20240905202615347.png)

(image from: Deep Learning with TensorFlow and Keras: Build and deploy supervised, unsupervised, deep, and reinforcement learning models, 3rd Edition)

>  Convolutional Neural Networks (CNNs) are a specialized kind of neural network used primarily to process data that has a grid-like topology, such as images, which can be considered as a grid of pixel values.

<br><br>

#### Key Components of CNNs

1. **Convolutional Layers:**
   
   - **Functionality:** These layers perform the <u>convolution operation</u>, which involves sliding a set of <u>learnable filters (or kernels) over the input image</u>. At each position, <u>a dot product is computed between the filter and the part of the image it covers.</u> This operation extracts features such as edges, corners, and other textures.
   - **Output:** The result is a feature map that gives the responses of the filter at every spatial position. The process is repeated <u>with multiple filters to obtain multiple feature maps</u>, which can be thought of as filtered versions of the image, each emphasizing different features.
   
   <Br>
   
2. **Activation Function:**
   - **ReLU (Rectified Linear Unit):** Most commonly used activation function in CNNs that introduces non-linearity to the model. The function is applied to each pixel of the feature map and replaces all negative pixel values in the feature map with zero. This is done to add the ability to capture non-linearities in the data.

   <br>
   
3. **Pooling Layers:**
   - **Purpose:** Pooling (subsampling or downsampling) reduces the dimensionality of each feature map but retains the most important information. Pooling layers help to make the representation smaller and more manageable and introduce basic translation invariance to the internal representation.
   - **Types:** Max pooling and average pooling are the most common forms. Max pooling returns the maximum value from the portion of the image covered by the Pool filter. Average pooling returns the average of all values from the portion of the image covered by the Pool filter.

   <br>
   
4. **Fully Connected (Dense) Layers:**
   - **Integration:** After several convolutional and pooling layers, the high-level reasoning in the neural network is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular artificial neural networks. Their output is computed by a matrix multiplication followed by a bias offset.
   - **Role:** These layers typically come at the end of a CNN architecture and are used to perform classification on the features extracted by the convolutions and pooled layers.

   <br>
   
5. **Normalization Layer (Batch Normalization):**
   - **Function:** Batch normalization is often inserted between convolutional layers and their activation functions to normalize the input layer by adjusting and scaling activations. This makes the network faster and more stable through normalization of the input layer by re-centering and re-scaling.
   
   <br><Br>

#### Working of CNNs
- **Input:** The input to a CNN is typically an image, which is processed through a series of convolutional, nonlinear layer, pooling, and fully connected layers.
- **Feature Extraction:** The convolutional and pooling layers act as feature extractors from the input image, reducing its spatial size while increasing the depth of the feature maps containing more complex encoded features of the input.
- **Classification:** After several convolutional and pooling layers, the high-dimensional feature maps are flattened and fed into fully connected layers for classification or regression.

<br><br>

#### Advantages of CNNs
- **Parameter Sharing:** Reduces the number of parameters, making the network less prone to overfitting, especially when dealing with high-dimensional input data.
- **Local Connectivity:** Focusing on local connectivity keeps the computation and model manageable by limiting connections to neurons of nearby regions.
