---
title: "Day21 Probability Review (3)"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, probability, statReview, TIL_24]
toc: true 
---

# Continuous Probability Distribution & Markov Chains

<img src="/blog/images/2024-06-14-TIL24_Day21/4AEBBBE4-BEF6-45D0-9972-46D073B1B6FC_1_105_c.jpeg">

<br><br>

*(Ace the Data Science Interview: 201 Real Interview Questions Asked By FAANG, Tech Startups, & Wall Street)*

### Probability Distribution

> Different probability distributions can be applied to specific situations. For instance, we can calculate the probability of a specific event occurring by using the distribution's probability density function (PDF).

#### 2. Continous Probability Distributions

The <u>uniform distribution</u> assumes a constant probability of a value falling between the intervals $a$ to $b$. Its PDF is

<center>
  $f(x) = \frac{1}{(b-a)}$ <br><br>
Mean: $\mu = \frac{a+b}{2}$ <br>
Variance: $\delta^2 = \frac{(b-a)^2}{12}$<br><br>
</center>

The most common applications for a uniform distribution are in sampling (random number generation, for example) and hypothesis testing cases. 

The <u>exponential distribution</u> provides the probability of the time between events occurring in a *Poisson* process with a given rate parameter $\lambda$. It's PDF is

<center>
  $f(x) = \lambda e^{- \lambda x}$ <br><br>
  Mean: $\mu = \frac{1}{\lambda}$ <br>
  Variance: $\delta^2 = \frac{1}{\lambda^2}$<br><br>
</center>

The exponential distribution is commonly used for wait times, such as the time between customer purchases or credit defaults. One of its most useful properties is "memorylessness," which gives rise to natural questions about the distribution.

The <u>normal distribution</u> is a probability distribution that follows the well-known bell curve pattern over a specific range. Given a particular mean and variance, its PDf is:

<center>
  $f(x) = \frac{1}{\sqrt{2 \pi \delta^2}} \text{exp}- \big(\frac{(x-\mu)^2}{2 \delta^2})$<br><br>
  Mean: $\mu = \mu$<br>
  Variance: $\delta^2 = \delta^2$<br><br>
</center>



<center>
  <img src="/blog/images/2024-06-14-TIL24_Day21/image-20240731162358056.png">
  <I>(Image:https://en.wikipedia.org/wiki/Probability_distribution)</I>
</center>

Many real-life applications frequently rely on the normal distribution due to its natural fit and the Central Limit Theorem (CLT). Thus, it is crucial to remember the probability density function (PDF) of the normal distribution.

<br><br>

### Markov Chains

> A Markov chain is a process in which there is a finite set of states, and the probability of being in a particular state is only dependent on the previous state. 



<I>(https://builtin.com/machine-learning/markov-chain)</I>

A Markov chain is a stochastic model created by Andrey Markov that describes <u>the probability of a sequence of events occurring based on the state of the previous event</u>. It is a widely used and easily understandable model that is frequently employed in industries dealing with sequential data, such as finance. Even Google's page rank algorithm, which determines the priority of links in its search engine results, is a type of Markov chain. Utilizing mathematical principles, this model leverages observations to forecast future events.

The primary objective of the Markov process is <u>to determine the probability of moving from one state to another.</u> A key attraction of the Markov process is that the future state of a stochastic variable depends solely on its present state. The stochastic variable is informally defined as a variable whose values are based on the results of random events.

The term "**memorylessness**" in mathematics refers to a property of probability distributions where the time it takes for an event to occur does not depend on how much time has already passed. In a Markov process, <u>predictions are conditional on their current state and independent of past and future states</u>.

The Markov process has its benefits in a scenario <u>where you want to predict words or sentences based on previously entered text.</u> The downside is that <u>you wonâ€™t be able to predict text based on context from a previous state of the model</u>, a common problem in natural language processing (NLP).

![image-20240731164121316](/images/2024-06-14-TIL24_Day21/image-20240731164121316.png)

<I>(https://towardsdatascience.com/markov-chain-analysis-and-simulation-using-python-4507cee0b06e)</I>

<br>

![image-20240731164229236](/images/2024-06-14-TIL24_Day21/image-20240731164229236.png)

<I>(https://www.geeksforgeeks.org/markov-chains-in-nlp/)</I>

For instance, in natural language processing (NLP), we utilize the Markov chain as described earlier. When creating a sequence of weather states, we begin with an initial state and utilize the transition probabilities to randomly choose the next state. This process is repeated to generate a sequence of weather states.

<br><br>

