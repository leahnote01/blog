---
title: "Day16 ML Review - R-squared (3)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [mlReview,statReview,TIL_24]
toc: true 
---

# Further Analysis on R-Squared 

<img src="/blog/images/2024-06-05-TIL24_Day16/0F09AEA5-9006-4733-BA5E-3688CF0EAC82_1_105_c.jpeg">

There are several definitions of $R^2$ that are only sometimes equivalent. One class of such cases includes <u>simple linear regression</u> where $r^2$ is used instead of $R^2$. When only an intercept is included, then $r^2$ is simply the square of the sample correlation coefficient (i.e., r) between the observed outcomes and the observed predictor values. *If additional regressors are included*, $R^2$ is the *square of the multiple correlation coefficient*. In both cases, the coefficient of determination normally ranges **from 0 to 1.** <br><br>

There are cases where $R^2$ **can yield negative values.** This can arise when the predictions compared to the corresponding outcomes have not been derived from a model-fitting procedure using those data. Even if a model-fitting procedure has been used, $R^2$ may still be negative, for example, when linear regression is conducted without including an intercept for when a non-linear function is used to fit the data. In cases where negative values arise, the mean of the data better fits the outcomes than the fitted function values, according to this particular criterion.
