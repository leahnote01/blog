---
title: "Day95 Deep Learning Lecture Review - Lecture 14"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [dlReview, CLIP, ResNet, SBERT, fine-tuning, prompt engineering, TIL_24]
toc: true 
---

# AI Ethics; AI Safety, Key Issues, **AGI (Artificial General Intelligence)**, and Current AI Models' Challenges

![73103FEF-CED1-4907-9AA3-1304DBAE6BA1](/images/2024-10-31-TIL24_Day95_DL/73103FEF-CED1-4907-9AA3-1304DBAE6BA1.jpeg)

> AI has evolved significantly recently, transforming various industries by enhancing efficiency and creating new opportunities. In this context, it is crucial to understand AI Ethics, which is essential for guiding the responsible development and use of artificial intelligence technologies. By prioritizing these ethical considerations, we can ensure that AI benefits society and mitigates potential risks associated with its adoption. 

The summary of this posting is provided below for your convenience and understanding!

 **Model & System Cards**:

- **Model Cards**: Provide details on AI models, including intended use, performance metrics, evaluation data, and ethical considerations.
- **System Cards**: Explain the operation of combined AI systems, acknowledging that these systems can evolve.

**AI Safety, Ethics, and Machine Morality**:

- **AI Safety**: Focuses on preventing accidents or misuse of AI systems, including existential risks.
- **AI Ethics**: Centers on responsible AI use, with attention to current issues like bias.
- **Machine Morality**: Investigates the moral behavior of AI systems.

**Critical Issues in AI Ethics & Safety**:

- **Bias Mitigation**: Tackling inherent biases in AI training data.
- **Model Monitoring**: Includes uncertainty estimation and detecting out-of-distribution (OOD) inputs or malicious use.
- **Model Robustness**: Ensures resilience to adversarial or degraded inputs, distribution shifts, and dataset bias.
- **AI Alignment**: Aims to align AI with intended ethical guidelines to prevent misuse, including research in reinforcement learning with human feedback (RLHF).
- **Weaponization of AI**: Discusses AI applications in autonomous weapons and cybersecurity.

**Social and Economic Impact**:

- **Social Manipulation**: Concerns over AI-generated media and misinformation.
- **Job Automation**: Predicted impacts on employment and potential solutions like universal basic income (UBI).
- **AI in Media**: Effects of generative AI on creative industries and related ethical concerns.

**AGI (Artificial General Intelligence)**:

- **Definition**: AGI would have human-level intellectual capabilities and is differentiated from today's "narrow AI."
- **Existential Risks**: Discuss potential global threats AGI poses if not correctly aligned, including the "paperclip maximizer" scenario from Nick Bostrom’s thought experiment.

**Challenges for Current AI Models**:

- Limitations like prompt sensitivity, planning deficiencies, lack of long-term memory, and issues with transparency and interpretability in large language models (e.g., GPT-4).<br><br><Br>



### Model & System Cards

#### AI Model Cards

Image Source: [Google Model Cards](https://modelcards.withgoogle.com/about)

![image-20241103143730651](/images/2024-10-31-TIL24_Day95_DL/image-20241103143730651.png)

- Model details: license, training methods
- Intended Use-- It may be specified as an out-of-scope use case.
- Metrics: Performance evaluation information
- Training Data: Often omitted
- Quantitative Analyses: Results on evaluation data
- Ethical considerations
- Caveats and recommendations<br><Br>

**AI System Cards**

Image Source: [Meta Blog - System Cards](https://ai.meta.com/blog/system-cards-a-new-resource-for-understanding-how-ai-systems-work/)

![image-20241103143847147](/images/2024-10-31-TIL24_Day95_DL/image-20241103143847147.png)

- It explains how AI and potentially non-AI models work together to accomplish a task.
- System cards aren’t definitive since AI systems can evolve. <br>
  – Model cards assume the system is frozen in time.<br><Br>

#### Red Teaming

- Companies often employ “red teams” to assess the limitations and risks of an AI system.
- Red teams may be internal, external, or both.
- For example, GPT-4V and GPT-4 used externa red teams.<Br><br>



#### GPT-4V System Cards

- Explains how the system was evaluated and its limitations.
- But it omits what it was trained on and training details.



![image-20241103144304986](/images/2024-10-31-TIL24_Day95_DL/image-20241103144304986.png)

Image Source: GPt-4V System Card from Open AI

<br><br>

### AI Ethics

- How can we determine if these systems are fair and appropriate?

- Definition

  - AI Safety: An interdisciplinary field <u>concerned with preventing accidents, misuse, or harmful consequences due to AI systems</u>. The community is very concerned about the existential risk of future AI.
  - AI Ethics: <u>Moral principles and techniques intended to inform the development and responsible use of AI.</u> Much of the focus is on bias in AI and the responsible usage of near-term systems.
  - Machine Morality: Research concerning designing AIs that behave morally

- However, there is a lot of overlap between the three definitions. This is due to different communities with different focuses wanting their own phrase for what they do.

- 

  

