---
title: "Day11 ML Review - Gradient Descent"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, TIL_24]
toc: true
---

# Overview of Gradient Descent

<img src="/blog/images/2024-05-28-TIL24_Day11/468E21DA-2133-4F40-851E-9DF4C50AC71B.jpeg" alt="day11in">

Mostly from <https://builtin.com/data-science/gradient-descent>

<br><br>

> Gradient Descent is a fundamental **optimization algorithm for finding a local minimum of a differentiable function.** In machine learning, gradient descent is simply used **to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible**.

“A gradient measures **how much the output of a function changes** if you change the inputs a little bit.”

<br>

### Basic Concept

The core idea behind gradient descent is to iteratively adjust the parameters of a model to minimize the target function. The algorithm uses the function's gradient (the vector of partial derivatives) at the current point to determine the direction in which the function decreases most rapidly. The parameters are then updated in the opposite direction of the gradient, hence moving towards the function's minimum.

<br>

#### **Steps in Gradient Descent**

1. **Initialization**: Start with initial guesses for the parameters. This can be random or based on some heuristic.

2. **Compute Gradient**: Calculate the cost function's gradient with respect to each parameter. The gradient indicates the direction of the steepest ascent in the cost function.

3. **Update Parameters**: Adjust the parameters in the opposite direction of the gradient. This is done using the formula:

   <center>

   $$
   \theta = \theta - \alpha \cdot \nabla_\theta J(\theta)
   $$

   </center>

   Where:
      - $\theta$ represents the parameters.

      - $\alpha$ is the learning rate, a tuning parameter that determines the step size during the update.

      - $\nabla_\theta J(\theta)$ is **the gradient of the cost function** at the current parameters. 

        <br>

4. Repeat: Repeat the process until the cost function converges to a minimum or until a maximum number of iterations is reached.

<br><br>

#### **Key Considerations**

- **Learning Rate $\alpha$**: The choice of learning rate is crucial. <u>Too small $\alpha$ rate makes the convergence slow</u>, while <u>too large can lead to overshooting</u> the minimum or even divergence.
- **Convergence**: Determining when the algorithm has converged to a minimum can be non-trivial. Common criteria include setting a maximum number of iterations or stopping when the change in cost function between iterations is below a certain threshold.  
- Feature Scaling: Gradient descent can converge much faster if all features are on a similar scale and close to normally distributed. Techniques like feature normalization or standardization are often used prior to model training. 
