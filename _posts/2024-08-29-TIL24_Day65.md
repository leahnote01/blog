---
title: "Day65 ML Review - Ensemble Method (4)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [mlReview, classifier, ensembleMethod, TIL_24]
toc: true 
---

# (Editing) Bagging

<img src="/blog/images/2024-08-29-TIL24_Day65/BAD51C87-04C0-4138-A121-F8B29E7D989E-4967013.jpeg"><br><br>

>  In contrast to using the identical training dataset for fitting each classifier in the ensemble, we utilize **bootstrap samples**, <u>random samples drawn with replacements from the original training dataset</u>. This approach is why bagging is also referred to as **bootstrap aggregating.**

![image-20240911170350775](/images/2024-08-29-TIL24_Day65/image-20240911170350775.png)

* Bagging, which stands for Bootstrap Aggregating, is a machine learning ensemble technique used to <u>improve the accuracy and reliability of predictive models</u>. It involves creating **multiple subsets of the training data** by using random sampling with replacement. These subsets are used to train multiple base learners, such as decision trees, neural networks, or other models.
