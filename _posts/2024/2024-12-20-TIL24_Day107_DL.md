---
title: "Day107 Deep Learning Lecture Review - HW4 - Model Calibration and Conformal Prediction"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../../
tag: [dlReview, TIL_24]
toc: true 
---

# Conformal Prediction Adaptive Prediction Set,

![110BCDEE-4EA5-47BD-877B-D706C51FB0B2_1_105_c](../../images/2024-12-20-TIL24_Day107_DL/110BCDEE-4EA5-47BD-877B-D706C51FB0B2_1_105_c.jpeg)<br><br>

**Model Calibration** ensures that predicted probabilities align with actual likelihood, which is crucial in high-stakes applications like medical diagnosis, finance, and autonomous systems. A well-calibrated model provides accurate <u>uncertainty estimation</u>, improving reliability and trustworthiness.

In this posting, I will explore:

1. **Model Calibration**: Using **Platt Scaling** and **Label Smoothing** to adjust a model's confidence levels.
2. **Conformal Prediction (CP)**: Generating **prediction sets** instead of single predictions to quantify uncertainty.





Uncertainty quantification is essential to deep learning applications, especially in critical domains like healthcare and autonomous systems. I explored **Conformal Prediction (CP)**, a framework that provides prediction sets with reliable coverage guarantees. The object was implementing **Naive and Adaptive Prediction Sets Algorithms** using a pre-trained ResNet Model.  <br><br>



### Understanding Conformal Prediction

Traditional deep learning models provide a single-point prediction with a confidence score (e.g., softmax probability). However, these confidence scores can be **miscalibrated** and fail to deliver reliable uncertainty estimates. **Conformal Prediction** addresses this limitation by generating **multiple possible prediction sets** while guaranteeing a **confidence level.** 

Mathematically, conformal prediction ensures that:  

<center>
$1-\alpha \leq P(Y \in \tau(X)) \leq 1-\alpha + \frac{1}{(n+1)}$ <br><Br>  
</center>

Where:

- $\alpha$ is the significance level,
- $X$ is the input,
- $Y$ is the true label,
- $\tau (X)$ is the prediction set.

The main concept is <u>to utilize a scoring function</u> to assess how closely the model's predictions align with the actual labels and then establish **quantiles** to form prediction sets. <br><br>

#### Implementing the Naïve Prediction Set Algorithm

The naïve method constructs a prediction set by including classes until the cumulative probability surpasses a predefined threshold. 

**Implementation Steps**

1. **Prepare the datasets**

   - Used `softmax_outputs.npy` for predicted probabilities.
   - Used `correct_classes.npy` for ground-truth labels. 

2. **Split the data**

   - The first **2000 samples** are used for **calibration**.
   - The remaining samples are for **validation**.

3. **Calculate scores**

   - The score function is simply the probability assigned to the true class: 

     <center>
       $s(X,Y) = 1-\hat{f}(X)_Y$ <br><br>
     </center>

   - Compute the quantile threshold $\hat{q}$ using:
     <center>
       $\hat{q} = Quantile(s_1, \dots, S_n; 1- \alpha $
     </center>

4. **Generate prediction sets**

   - Include the top $k$ classes until their cumulative probability exceeds $1-\hat{q}$.
   - **Iterate through softmax outputs** until the **cumulative probability surpasses** the threshold.  <br><Br>

**Results**

- **Empirical coverage: 98.66%**
- **Key observation:** The **naïve method** produces **small prediction sets** but can occasionally miss the true class, affecting reliability. 
- Coverage slightly below **99**% meaning some samples were **miclassified** without correction. <Br><br>



#### Imprementing the Adaptive Prediction Set Algorithm

The  ensures that the true label is always included by dynamically adjusting the prediction set.

**Implementation Steps**

1. **Score function:**

   - Instead of considering **only** the probability of the true label, accumulate **probabilities** until the true label is reached. 

   - **Ensure** that the true label is **always present.**  

     

     <center>
      $ s(X,Y) = \sum_{j=1}^k \hat{f}(X)_{\pi_j}$ <br><br>
     </center>





2. **Compute quantile threshold**
   - Compute the quantile threshold $\hat{q}$ based on the sorted scores.

3. **Generate Adaptive Prediction Sets**
   - **Continue adding classes** until the <u>true label is included.</u> <br><br>



**Results**

- **Empirical Coverage:** 99.72%
- **Higher coverage** than naïve method, ensuring the true label is always included.
- **Larger prediction sets,** which <u>reduces interpretability.</u><br><br>



### **Comparing Naïve vs. Adaptive Methods**

| Aspect              | Naïve Method                    | Adaptive Method                      |
| :------------------ | ------------------------------- | ------------------------------------ |
| Coverage            | 98.66%                          | 99.72%                               |
| Prediction Set Size | Smaller                         | Larger                               |
| Reliability         | Occasionally misses true labels | **Always** includes true labels      |
| Efficiency          | Faster                          | Slightly slower due to set expansion |

**Main Insights**

1. **Naïve method is efficient but unreliable**
   - It <u>sometimes omits</u> the true label, leading to <u>misclassification risks.</u>
   - <u>Smaller sets</u> improve interpretability, but at the cost of <u>lower coverage.</u>
2. **Adaptive method ensures full coverage but at a cost**
   - Always includes the <u>correct label</u>, making it more <u>reliable</u>.
   - <u>Larger sets reduce interpretability</u>, as multiple labels might be included unnecessarily.
3. **Trade-off: Interpretability vs. Coverage**
   - If <u>interpretability</u> is crucial, the <u>naïve</u> method is preferable.
   - If <u>accuracy</u> is the prority, the <u>adpative</u> method is the best choice. <br><br>

### Conclusion

Conformal Prediction provides a mathematically rigorous approach to **uncertainty quantification.** Through this homework, I could learn:

- <u>How to implement naïve and adaptive prediction sets.</u> 
- The <u>importance of quantile calibration</u> in deep learning.
- <u>Trade-offs</u> between compactness and reliability.

As deep learning models become increasingly deployed in real-world applications, techniques like conformal prediction will e essential for making reliable and interpretable AI systems. <br><Br>
