---
title: "Day26 ML Review - Perceptron (1)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [mlReview,classifier,TIL_24]
toc: true 
---

# **Choosing a Classification Algorithm Step by Step** - Training Perceptron (1)

<img src="/blog/images/2024-07-16-TIL24_Day26/FAE622BA-18CF-4AD8-85DD-E5699441DCF6.jpeg">

<br><br>

*(Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow 2, 3rd Edition)*

> Choosing the right classification algorithm for a particular problem involves practice and experience. Each algorithm has its <u>distinct characteristics</u> and is based on <u>specific assumptions</u>.

In practical terms, it's always advisable <u>to compare the performance of various learning algorithms to select the</u> best model for the specific problem. The selection of algorithms may vary based on factors such as t*he number of features or examples*, *the level of noise in the dataset*, and *whether the classes are linearly separable or not.*

Ultimately, the performance of a classifier, including computational performance and predictive power, heavily relies on **the underlying data available for learning**. The five main steps involved in training a supervised machine learning algorithm can be summarized as follows:

1. Selecting features and collecting labeled training examples.
2. Choosing a performance metric.
3. Choosing a classifier and optimization algorithm.
4. Evaluating the performance of the model.
5. Tuning the algorithm.

<br>



## Step by step of Training Perceptron

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3 random_state=1, stratify=y)
```

Using integer labels is recommended to avoid technical issues and improve computational performance due to a smaller memory footprint. Also, most machine-learning libraries follow the convention of encoding class labels as integers.

We will further split the dataset into training and test datasets <u>to evaluate how well a trained model performs on unseen data.</u>

Using the `train_test_split` function from sci-kit-learn’s `model_selection` module with the `test_size=0.3` line, we randomly split the `x` and `y` arrays into 30 percent test data and 70 percent training data. 

Note that the `train_test_split` function already shuffles the training datasets internally before splitting; otherwise, all examples from class 0 and class 1 would have ended up in the training datasets, and the test dataset would consist of 45 examples from class ‘2’ only. 

Via the `random_state` parameter, we provided a fixed random seed (random_state=1) for the internal <u>pseudo-random number generator</u> used for shuffling the datasets before splitting. Using such a fixed `random_state` ensures that our results are reproducible.

Lastly, we took advantage of stratification's built-in support via `stratify=y`. In this context, stratification means that the `train_test_split` method returns training and test subsets with the same class label proportions as the input dataset. We can use NumPy’s `bin_count` function, which counts the number of occurrences of each value in an array, to verify this is true.

Many machine learning and optimization algorithms also require feature scaling for optimal performance. We will standardize the feature using the `StandardScaler` class from sci-kit-learn’s `preprocessing` module. 

<br><br>

