---
title: "Day07 ML Review - Linear Regression"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, TIL_24]
toc: true
---

# Supervised Learning - Linear Regression 

<img src="/blog/images/2024-05-22-TIL24_Day7/8915EDEF-F6CE-4B6A-867B-A331A7853217.jpeg" alt="day07in">

#### Overview

>Linear regression is a method for modeling the linear relationship between a dependent variable and one or more independent variables. Linear regression aims **to find a linear equation that best predicts the dependent variabl**e from the independent variables.

Linear Regression is a data analysis technique that <u>predicts the value of unknown data using known, related data values.</u> It creates a mathematical model using a linear equation to represent the relationship between a dependent variable and one or more independent variables.  <br>

For instance, if you have data on your expenses and income for the past year, linear regression can help determine if your expenses are half your income. This analysis allows you to predict future expenses by halving the projected income. Linear regression models are simple and offer straightforward mathematical formulas for making predictions. This statistical technique is widely used in software and computing applications.<br>

In Machine Learning, algorithms analyze large data sets and use that data to calculate linear regression equations. **Data Scientists first train an algorithm on a known or labeled data set and then use that algorithm to predict unknown values**. 

<br><Br>

#### Simple Linear Regression

The model predicts the outcome based on a single independent variable. The relationship between the dependent variable $y$ and the independent variable $x$ is defined by the equation: <br>
$$
\\ y= \beta_0 + \beta_1x + \epsilon \\
$$
<br>

- $\beta_0$ is the intercept of the line.
- $\beta_1$ is the slope of the line, which represents the effect of the independent variable on the dependent variable.
- $\epsilon$ is the error term, accounting for the variability in $y$ not explained by $x$.

<br><br>

#### Multivariate Linear Regression

$$
\\ y=\beta_0+\beta_1x_1+\beta_2x_2+ \dots +\beta_nx_n+ \epsilon
\\
$$

<br>

The multiple linear regression model counts on the multiple independent variables. <br>

It is typically used for <u>predicting continuous values and forecasting</u>, but it can be used for classification tasks, such as <u>binary classification.</u> In such cases, a threshold is set, and *values below the threshold predict one class, while values above predict another.* <br>

Linear regression is a **parametric** model that assumes a linear relationship between the input and output variables. <br><br>



#### Limitations of Linear Regression

- **Linearity Assumption**: The biggest limitation is the assumption of linearity. Linear Regression assumes the relationship between the dependent and independent variables is linear. This can be overly simplistic as real-world data often exhibits non-linear patterns.
- **Influence of Outliers**: Linear regression models are <u>highly sensitive to outlier values.</u>  Outliers can have a disproportionately large effect on the fit of the model, often skewing the entire regression line.
- **Homoscedasticity**: Linear regression assumes the variance of <u>residual errors is consistent across all levels of the independent variables</u> (homoscedasticity). The model's predictions become less reliable if the error variance changes (heteroscedasticity).
- **Independence**: The model assumes that the observations are independent of each other. In cases where there is autocorrelation between observations (as often found in time series data), the standard model fitting procedures can yield unreliable estimates.









