---
title: "Day67 (2) Deep Learning Review - CNN (1)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [dlReview, neuralNetwork, CNN, TIL_24]
toc: true 
---

# Convolutional Neuron Network (1)

<img src="/blog/images/2024-09-04-TIL24_Day67_DL/E078B106-915B-47B6-B14F-816FCBFA5E13.jpeg"><br><br>

## The building blocks of CNNs

>  Certain NNs, such as CNNs, can automatically learn the features from raw data that are most useful for a particular task.

<br>

### Understanding CNNs and Feature Hierarchies

<center>
  <img src="/blog/images/2024-09-04-TIL24_Day67_DL/image-20240905202615347.png" width="80%"><br>
  <Font size= 3pt><I>(image from: Deep Learning with TensorFlow and Keras: Build and deploy supervised, unsupervised, deep, and reinforcement learning models, 3rd Edition)</I></Font> <br><br>
</center>
<br><br>

A Convolutional Neural Network (CNN) analyzes an input image <u>by breaking it down into smaller sections of pixels</u> and then computing **feature maps** based on these local patches.

![image-20240905204902661](/images/2024-09-04-TIL24_Day67_2_DL/image-20240905204902661.png)

This patch of pixels is known as the local receptive field. CNNs typically excel in image-related tasks, mainly due to two essential ideas:

- Sparse connectivity: A single element in the feature map is only connected to a small patch of pixels.
- Parameter sharing: The same weights are used for different input image patches. 

<br>

![image-20240905210802353](/images/2024-09-04-TIL24_Day67_2_DL/image-20240905210802353.png)

(https://encord.com/blog/convolutional-neural-networks-explained/)



When we switch from a traditional, fully connected Multilayer Perceptron (MLP) to a convolutional layer, <u>a significant reduction in the network's weight (parameter) count is observed</u>. This modification improves the network's capacity to capture crucial features in the data. In the context of image data, it is reasonable <u>to assume that nearby pixels are more relevant to each other than pixels that are far apart</u>.

<br>

Convolutional Neural Networks (CNNs) are structured with multiple layers of **convolutional** and **subsampling** operations, **followed by one or more fully connected layers at the end**. The fully connected layers essentially form a Multi-Layer Perceptron (MLP), where each input unit, $i$, is connected to every output unit, $j$, using a weight denoted as $W_{ij}$.

<br>

The subsampling layers 
