---
title: "Day67 (2) Deep Learning Review - CNN (1)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [dlReview, neuralNetwork, CNN, TIL_24]
toc: true 
---

# Convolutional Neural Network (1)

<img src="/blog/images/2024-09-04-TIL24_Day67_DL/E078B106-915B-47B6-B14F-816FCBFA5E13.jpeg"><br><br>

## The building blocks of CNNs

>  Certain neuron networks, such as CNNs, can automatically learn the features from raw data that are most useful for a particular task.

<br>

### Understanding CNNs and Feature Hierarchies

A Convolutional Neural Network (CNN) analyzes an input image <u>by breaking it down into smaller sections of pixels</u> and then computing **feature maps** based on these local patches.

<center>
  <img src="/blog/images/2024-09-04-TIL24_Day67_2_DL/image-20240905204902661.png" width="80%"><br><br>
</center>



This patch of pixels is known as the local receptive field. CNNs typically excel in image-related tasks, mainly due to two essential ideas:

- Sparse connectivity: A single element in the feature map is only connected to a small patch of pixels.
- Parameter sharing: The same weights are used for different input image patches. 

<br>

<center>
  <img src="/blog/images/2024-09-04-TIL24_Day67_2_DL/image-20240905210802353.png" width="90%"><br>
  <font size="3pt"><I>(https://encord.com/blog/convolutional-neural-networks-explained/)</I></font><br><br>
</center>





When we switch from a traditional, fully connected Multilayer Perceptron (MLP) to a convolutional layer, <u>a significant reduction in the network's weight (parameter) count is observed</u>. This modification improves the network's capacity to capture crucial features in the data. In the context of image data, it is reasonable <u>to assume that nearby pixels are more relevant to each other than pixels that are far apart</u>.

<br>

Convolutional Neural Networks (CNNs) are structured with multiple layers of **convolutional** and **subsampling** operations, **followed by one or more fully connected layers at the end**. The fully connected layers essentially form a Multi-Layer Perceptron (MLP), where each input unit, $i$, is connected to every output unit, $j$, using a weight denoted as $W_{ij}$.

<br>

The subsampling layers, also known as **pooling layers**, do not have any learnable parameters. This means they do not have adjustable weights or bias units during training. In contrast, both the convolutional and fully connected layers have weights and biases that are modified and optimized as the network is trained.

<br><br>

### The Architecture of CNNs

> The architecture of a Convolutional Neural Network (CNN) is designed to take advantage of the 2D structure of an input image. This is achieved through the use of <u>convolutional layers, pooling layers, and fully connected layers.</u> Each type of layer performs a distinct function and contributes to the network's ability to perform complex image recognition tasks.

<br>

![image-20240906170640637](/images/2024-09-04-TIL24_Day67_2_DL/image-20240906170640637.png)

 Hereâ€™s a detailed breakdown of the typical structure of a CNN:

1. **Input Layer**

- **Function:** The input layer is the entry point for data into the CNN. It handles the raw pixel values of the image.
- **Format:** Images are represented as tensors of shape $(\text{height}, \text{width}, \text{channels})$. For standard color images, three channels correspond to the RGB (Red, Green, Blue) color model. This structured format allows the network to appropriately process different aspects of the image through its depth (channels), recognizing colors and their intensities.

<br>

2. **Convolutional Layers**

- **Function:** Convolutional layers are the core building blocks of a CNN. They <u>apply several filters to the input image to create feature maps.</u> These filters are designed to detect specific features such as edges, colors, or textures.
- **Mechanism:** Each filter is a small matrix of weights, which is convolved across the width and height of the input image, computing dot products at each position. The result is a feature map that represents the presence and intensity of detected features across the spatial dimensions of the image.
- **Output:** The output from a convolutional layer is a set of feature maps, each corresponding to one filter. As layers progress, filters can detect increasingly complex features by building upon the simpler features identified in preceding layers.

3. **Activation Layer (ReLU)**

- **Function:** Activation functions like ReLU (Rectified Linear Unit) introduce non-linearity to the network. ReLU is defined as \( \max(0, x) \), which effectively sets all negative values in the input tensor to zero.
- **Purpose:** The non-linearity is crucial because it allows the network to learn and model more complex patterns. Without non-linear functions, the network would effectively behave as a linear classifier, which is less powerful and unable to model the complex relationships found in real-world image data.

4. **Pooling (Subsampling) Layer**

- **Function:** Pooling layers reduce the spatial dimensions (width and height) of each feature map but retain the most significant information. This subsampling helps in reducing the computational load and the number of parameters.
- **Types:** 
  - **Max Pooling:** Returns the maximum value from the portion of the image covered by the pool. It is useful for capturing the most prominent feature activations.
  - **Average Pooling:** Returns the average of all values from the portion of the image, providing a smoothed feature map.
- **Benefits:** Pooling contributes to the network's invariance to small translations, rotations, and scale changes, making it robust to variations in the position and orientation of objects within the image.

5. **Fully Connected (Dense) Layers**

- **Function:** These layers connect every input to every output in a flat, fully connected manner, akin to traditional neural networks. After convolutional and pooling layers have extracted features and reduced their dimensions, dense layers are used to interpret these features and make decisions (e.g., classification).
- **Purpose:** They play a critical role in combining all the learned features effectively across the entire image to perform tasks such as classifying the image into predefined categories.

6. **Output Layer**

- **Function:** The final layer in a CNN, which is typically a fully connected layer. It outputs the final predictions of the network.
- **Activation Function:** For classification tasks, a softmax activation function is often applied at the output layer. The softmax function converts raw score logits into probabilities by taking the exponential of each output and then normalizing these values by dividing by the sum of all exponentials. This gives a probability distribution over the classes, facilitating easy interpretation of the results.
