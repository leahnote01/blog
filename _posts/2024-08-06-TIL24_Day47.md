---
title: "Day47 ML Review - Data Preprocessing (1)"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, classifier, dataPreprocessing, TIL_24]
toc: true 
---

# Handling Missing Data & Categorical Data

<img src="/blog/images/2024-08-06-TIL24_Day47/IMG_1486.JPG"><br><br>

>Preprocessing datasets is a critical step in machine learning and data analysis, as it prepares raw data for modeling by cleaning, transforming, and organizing it. Proper preprocessing can significantly improve the performance of a model. Hereâ€™s a step-by-step guide to the common preprocessing steps:



## Dealing with Missing Data

We typically see missing values as blank spaces in our data table or as placeholder strings such as `NaN`, which stands for "not a number," or `NULL` ( a commonly used indicator of unknown values in relational databases). As most computational tools are unable to handle these missing values, it is crucial that we take care of those missing values before we proceed with further analyses. 

We can use the `isnull` method to return a `DataFrame` with Boolean values that indicate whether a cell contains a numeric value (`False`) or if data is missing (`True`). Using the `sum` method, we can then return the number of missing values per column as follows. This way, we can count the number of missing values per column.

```python
import pandas as pd
df = pd.read_csv(df)
df.isnull().sum()
```

<br><Br>

### Eliminating Missing Values

If a dataset has a significant number of missing values in its rows or columns, the simplest approach may be to remove those rows or columns. Rows with missing values can easily be dropped via the `dropna` method. 

```python
df.dropna(axis=0)
```



Similarly, we can drop columns that have at least one `NaN` in any row by setting the `axis` argument to `1`. 

```python
df.dropna(axis=1)
```



The `dropna` method supports several additional parameters that can come in handy as follows.

```python
# only drop rows where all columns all NaN
df.dropna(how='all')

# drop rows that have fewer than 4 real values
df.dropna(thresh=4)

# only drop rows where NaN appears in specific columns (here: 'C')
df.dropna(subset=['C'])
```

Although removing all `NaN` columns looks very convenient, it also comes with certain disadvantages. For example, we may end up removing too many samples, which will make a reliable analysis impossible. Or, if we remove too many feature columns, we risk losing valuable information that our classifier needs to discriminate between classes.<br><br>



### Imputing Missing Values

In another way, we can use different interpolation techniques to estimate the missing values from the other training examples in our dataset.

- **Mean/Median/Mode Imputation**: Replace missing values with the mean, median, or mode of the column. 
- **Forward/Backward Fill**: Use the previous or next value in the column to fill in the missing values (mainly for time series data). 
- **Interpolation**: Estimate missing values using interpolation methods (useful for time series data). 
- **Model-Based Imputation**: Utilize machine learning models to predict and fill in missing values.

For example, we can use `mean imputation,` where we replace the missing value with the mean value of the entire feature column. A convenient way to achieve this is by using the `SimpleImputer` class from scikit-learn as follows.

```python
from sklearn.impute import SimpleImputer
import numpy as np
imr = SimpleImputer(missing_values=np.nan, strategy='mean')
imr = imr.fit(df.values)
imputed_data = imr.transform(df.values)
```



In our data manipulation process, we addressed missing values `NaN` by filling them with the mean of each feature column. Additionally, we discussed alternatives in `strategies` parameter such as using the `median` or `most_frequent`  for imputation. The `most_frequent` option is particularly useful when dealing with categorical feature values, such as columns representing color names (e.g., red, green, and blue).



Another approach to address missing values is to utilize Pandas' `fillna` method and specify an imputation method as an argument. For instance, within the `DataFrame` object in Pandas, we can seamlessly implement mean imputation with the following command:

```python
df.fillna(df.mean())
```

<br><br>



#### Side Note

The following figures illustrate how a transformer, fitted on the training data, transforms a training dataset and a new test dataset. 

<img src="/blog/images/2024-08-06-TIL24_Day47/image-20240814182319788.png" width="50%">

![image-20240814182454162](/images/2024-08-06-TIL24_Day47/image-20240814182454162.png)

<br><br>

