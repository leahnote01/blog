---
title: "Day90 Deep Learning Lecture Review - HW0"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [dlReview, softmax, activation function, TIL_24]
toc: true 
---

# Softmax Properties, 

![C38292DC-87CA-412E-BCEE-7415218C78CE_1_105_c](/images/2024-10-14-TIL24_Day91_DL/C38292DC-87CA-412E-BCEE-7415218C78CE_1_105_c.jpeg)

> The **softmax function** is a common activation function used in machine learning, particularly in the final layer of a neural network for **classification tasks**. It converts raw model outputs (often called logits) into probabilities that sum to 1. Below, I'll describe its properties and why they are useful.



