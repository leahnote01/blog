---
title: "Day48 ML Review - Data Preprocessing (2)"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, classifier, dataPreprocessing, TIL_24]
toc: true 
---

# Handling Categorical Data - Converting, Ordinal Encoding, and One-Hot Encoding

<img src="/blog/images/2024-08-07-TIL24_Day48/F6EB4DB5-A21F-4352-AF12-57B2710381F1_1_102_o.jpeg"><br><br>



## Dealing with Categorical Data

When discussing categorical data, distinguishing between <u>ordinal</u> and <u>nominal</u> features is essential. Ordinal features are categorical values that can be sorted or ordered, such as t-shirt sizes. On the other hand, nominal features do not imply any order, like t-shirt colors. Let's make a data frame example as below. 

```python
import pandas as pd
df = pd.DataFrame([
 ['green', 'M', 10.1, 'class2'],
  ['red', 'L', 13.5, 'class1'],
  ['blue', 'XL', 15.3, 'class2']])
df.columns = ['color', 'size', 'price', 'class-label']
```

<br><br>

### 1. Mapping Ordinal Features

To ensure that the learning algorithm interprets the ordinal features correctly, we need to convert the categorical string values into integers. Unfortunately, no convenient function can automatically derive the correct order of the labels on features, so we have to define the mapping manually.

```python
size_mapping = {'XL' : 3, 
               'L': 2,
               'M', 1}
df['size'] = df['size'].map(size_mapping)
```

<br>

We can create a reverse-mapping dictionary to convert the integer values back to their original string representation later on. This dictionary, inv_size_mapping, can be defined as: 
```python
inv_size_mapping = {v: k for k, v in size_mapping.items()}
```
We can then use this dictionary with the Pandas `map` method in the transformed feature column. This process is similar to that of the `size_mapping` dictionary we previously used.

```python
df['size'].map(inv_size_mapping)
```

<br>

### 2. Encoding Class Labels

To avoid technical issues, it's recommended that class labels be provided as integer arrays. We can use a method similar to the one used for mapping ordinal features to encode the class labels. 

It's important to note that class labels are not ordinal, so <u>it doesn't matter which integer we assign to a specific label</u>. We can enumerate the class labels, starting at `0`.

```python
import numpy as np
class_mapping = {label: idx for idx, label in enumerate(np.unique(df['classlabel']))}
```

<br>

Then, we can use a mapping dictionary to convert the class labels into integers.

```python
df['classlabel'] = df['classlabel'].map(class_mapping)
```

<br>

To map the converted class labels back to their original string representation, we can reverse the key-value pairs in the mapping dictionary. 

```python
inv_class_mapping = {v: k for k, v in class_mapping.items()}
df['classlabel'] = df['classlabel'].map(inv_class_mapping)
```

<br>

Alternatively, we can use the convenient `LabelEncoder` class directly implemented in scikit-learn to achieve this. It's important to note that the `fit_transform` method is just a shortcut for calling fit and transform separately.

```python
 from sklearn.preprocessing import LabelEncoder
 class_le = LabelEncoder()
 y = class_le.fit_transform(df['classlabel'].values)
```

<br>

We can use the `inverse_transform` method to transform the integer class labels back into their original string representation.

```python
 class_le.inverse_transform(y)
```

<br>

### 3. Performing One-Hot Encoding on Nominal Features

In the earlier section on Mapping ordinal features, we converted the ordinal size feature into integers using a simple dictionary-mapping approach. As scikit-learn's classification estimators treat class labels as categorical data without any implied order (nominal), we conveniently used the `LabelEncoder` to encode the string labels into integers. It might seem that we could employ a similar approach to transform the nominal color column of our dataset as follows:

```python
 X = df[['color', 'size', 'price']].values
 color_le = LabelEncoder()
 X[:, 0] = color_le.fit_transform(X[:, 0])
```

<br>

After running the code, the first column of the NumPy array X now contains the new color values: `blue (0)`, `green (1`), and `red (2)`. Although the color values are not in any specific order, a learning algorithm will interpret green as larger than blue and red <u>as larger than green.</u> This assumption needs to be corrected, but the algorithm could still generate valuable results, although they may not be optimal.

To handle this issue, we can use a method known as **one-hot encoding**. This involves creating a new binary feature for **each unique value in the nominal feature column**. For instance, if we have a color feature with values like blue, green, and red, we would create new binary features for each color. Then, for each example, we would use <u>binary values to indicate the presence of a particular color</u> (e.g., blue=1, green=0, red=0). OneHotEncoder in scikit-learn's preprocessing module can be used to carry out this transformation.

```python
 from sklearn.preprocessing import OneHotEncoder
 X = df[['color', 'size', 'price']].values
 color_ohe = OneHotEncoder()
 color_ohe.fit_transform(X[:, 0].reshape(-1, 1)).toarray()
```



<br><br>

