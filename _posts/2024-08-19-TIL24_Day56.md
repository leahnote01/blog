---
title: "Day56 ML Review - Cross Validation "
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, classifier, crossValidation, kFold, TIL_24]
toc: true 
---

# Using K-fold Cross Validation to Assess Model Performance

<img src="/blog/images/2024-08-19-TIL24_Day56/A77B832A-568D-4275-8B7F-FFA21E129330.jpeg"><br><br>

> When constructing a machine learning model, it is essential to evaluate its performance based on data it has not been trained on. For example, if we train our model using a particular dataset, <u>we need to assess its performance when presented with new data that it has yet to see.</u>

As we've discussed before, a model can suffer from underfitting (high bias) if it's too simple or overfitting the training data (high variance) if it's too complex. The key is to evaluate our model meticulously to strike an acceptable balance between bias and variance.

We will check **holdout cross-validation** and **k-fold cross-validation**, which can help us to obtain reliable estimates of the model's generalization performance, that is, how well the model performs on unseen data.

<br>

## The Holdout Method

A classic and popular approach for estimating the generalization performance of machine 



<br><br>

