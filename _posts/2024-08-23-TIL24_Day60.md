---
title: "Day60 ML Review - Cross Validation (5)"
layout: single
classes: wide
categories: TIL_24
read_time: True
typora-root-url: ../
tag: [mlReview, classifier, crossValidation, TIL_24]
toc: true 
---

# ROC area Under The Curve (ROC AUC)

<img src="/blog/images/2024-08-23-TIL24_Day60/83B605C7-5ACE-47E4-9545-F7A09E7CBF4B_1_105_c.jpeg"><br><br>

<font size=3pt><I>Image and Explanation from <a href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc">Google Developer_ML Concepts Webpage</a> <br>(https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)</I></font>



## Key Concepts

> Receiver operating characteristic (ROC) graphs are useful tools for selecting classification models **based on their performance in terms of false positive rate (FPR) and true positive rate (TPR)**. These rates are calculated by adjusting the classifier's decision threshold. The diagonal line in an ROC graph represents random guessing, and any classification models falling below the diagonal line are considered worse than random guessing.

In an ideal scenario, a classifier would be positioned in the top-left corner of the graph, with a True Positive Rate (TPR) of 1 and a False Positive Rate (FPR) of 0, as below.

<center>
  <img src="/blog/images/2024-08-23-TIL24_Day60/image-20240829191426145.png" width="50%"><br><br>
</center>




Using the ROC curve, we can calculate the ROC area under the curve (ROC AUC) to evaluate a classification model's performance.

<center>
  <img src="/blog/images/2024-08-23-TIL24_Day60/image-20240829191522866.png" width="70%"><br><br><Br>
</center>





## AUC and ROC for Choosing the Model and Threshold

Area Under the Curve (AUC) is a helpful metric for <u>comparing the performance of two models</u>, provided that the dataset is balanced. When dealing with imbalanced datasets, using the precision-recall curve is better. The model **with a larger area under the curve is generally considered better.** 



<center>
  <img src="/blog/images/2024-08-23-TIL24_Day60/image-20240829191647241.png" width="50%"><br><br>
</center>

The points on a ROC curve that is closest to (0,1) indicate **a range of the best-performing thresholds** for the given model. As explained in the Thresholds, Confusion Matrix, and Choice of Metric and Tradeoffs sections, <u>the choice of threshold depends on which metric is most important for the specific use case</u>. Take into account points A, B, and C in the following diagram, each representing a threshold.

<center>
  <img src="/blog/images/2024-08-23-TIL24_Day60/image-20240829200110630.png" width="70%"><br><br>
</center>



<br><br>

