---
title: "Day134 - STAT Review: Classification (4)"
layout: single
classes: wide
categories: TIL_25
read_time: True
typora-root-url: ../../
tag: [StatReview, TIL_25]
toc: true 
---

# Practical Statistics for Data Scientists: Logistic Regression (2) (GLM, interpretation, and assessing the model)

![EFA0B434-2932-44F7-914B-E4CA95F0AD4F_1_105_c](../../images/2025-03-05-TIL25_Day134/EFA0B434-2932-44F7-914B-E4CA95F0AD4F_1_105_c.jpeg)<br><br>

### Logistic Regression and the GLM

In the logistic regression formula, the response represents the log odds of a binary outcome of 1. Since we only observe the binary outcome rather than the log odds, *specialized statistical methods are required to fit the equation*. 

> Logistic regression is **a specific case of a generalized linear model (GLM)** that was created to broaden the applications of linear regression.

#### What are GLMs?

Generalized Linear Models (GLMs) extend linear regression by introducing:

1. **A probability distribution (family)**
   - **Binomial** (for logistic regression)
   - **Poisson** (for count data)
   - **Gamma** (for modeling time to failure)
2. **A link function**
   - **Logit function** for logistic regression.
   - **Log function** for Poisson regression.

Logistic regression is the  <u>most common type of GLM</u>, where:

- The **response variable** follows a **binomial distribution** (0 or 1).
- The **logit link function** transforms probabilities into log-odds.

Other types of GLM in practice as follows.

- **Poisson Regression**: Used for count data (e.g., number of website visits).
- **Negative Binomial Regression**: Handles overdispersed count data.
- **Gamma Regression**: Used for modeling continuous positive responses like **time-to-failure.**

Unlike logistic regression, using GLMs with these models requires **a more nuanced approach and extra caution.** It's advisable to steer clear of them unless you are well-acquainted with their utility and potential drawbacks. 

<br>

#### Predicted Values from Logistic Regression

Logistic regression's predicted value is expressed **in log odds** : $\hat{Y} = \log(\text{Odds}(Y=1))$. **The logistic response** gives the predicted probability function:

<center>
  $\hat{p} = \frac{1}{1+e^{-\hat{Y}}}$<br><br>
</center>



For example, when we look at the predictions from the model `logistic+model` in *R*, 

```R
pred <- predict(logistic_model)
summary(pred)
---
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
-2.704774 -0.518825 -0.008539  0.002564  0.505061  3.509606
```

In *Python*, we can convert the probabilities into a data frame and use the `describe` method to get these characteristics of the distribution:

```python
pred = pd.DataFrame(logit_reg.predict_log_proba(X), 
                    columns=loan_data[outcome].cat.categories)
pred.describe()
```

 Converting these values to probabilities is a simple transform:

``` python
prob <- 1/(1 + exp(-pred))
> summary(prob)
---
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.06269 0.37313 0.49787 0.50000 0.62365 0.97096
```

The probabilities are directly available using the `predict_proba` methods in `scikit-learn`:

```python
pred = pd.DataFrame(logit_reg.predict_log_proba(X),
                    columns=loan_data[outcome].cat.categories)
pred.describe()
```

These values range from **0 to 1** and <u>do not indicate</u> whether the predicted value has been defaulted on or paid off. We could **set any value above 0.5 as default.** **However, a <u>lower threshold is usually better</u> when the aim is to find members of a rare class.** 

<br>

#### Interpreting the Coefficients and Odds Ratios



