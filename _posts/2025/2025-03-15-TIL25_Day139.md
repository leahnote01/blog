---
title: "Day139 - STAT Review: Statistical Machine Learning (1)"
layout: single
classes: wide
categories: TIL_25
read_time: True
typora-root-url: ../../
tag: [StatReview, TIL_25]
toc: true 
---

# Practical Statistics for Data Scientists: K-Nearest Neighbors (1) (Example, Distance Metrics, One Hot Encoder, Standardization)

![C2BE6DF8-A21E-42BF-86E8-12CD4D02F3CC_1_105_c](/images/2025-03-15-TIL25_Day139/C2BE6DF8-A21E-42BF-86E8-12CD4D02F3CC_1_105_c.jpeg)

<br>

## **What Is Statistical Machine Learning?**

**Statistical Machine Learning** refers to **data-driven, automated methods** used for prediction tasks like **classification** (e.g., "yes" vs. "no") and **regression** (predicting a continuous value).

- These techniques differ from **classical statistics**, which focuses on explaining relationships through fixed models (like linear regression).
- Instead, statistical machine learning methods let the data speak for itself without assuming a fixed structure (like linearity).

For examples,

- **K-Nearest Neighbors (KNN)**: Predict by looking at similar data points.
- **Ensemble Learning + Decision Trees**: Use multiple decision trees together (like Random Forests and Boosting) to get strong predictive results.

<br>

#### **Machine Learning vs. Statistics**

| Machine Learning                     | Statistics                           |
| ------------------------------------ | ------------------------------------ |
| Focuses on performance & scalability | Focuses on understanding & inference |
| Optimizes for predictive accuracy    | Explains underlying data structure   |
| Example: Boosting, Neural Nets       | Example: Generalized Linear Models   |

There's **no hard line** between them—both communities contribute to techniques like bagging and boosting.

<br>

### **K-Nearest Neighbors (KNN)**

KNN is a **simple** yet powerful technique. It doesn’t build a model—it **predicts directly from the data** by comparing a new point to nearby points in the training data.

#### How It Works:

1. For a new data point, find **$K$ nearest neighbors** (based on a distance metric).
2. If **classification**: <u>assign the majority class</u> among those neighbors.
3. If **regression**: <u>average the target values</u> of those neighbors.

<br>

#### Key Terms for K-Nearest Neighbors

- Neighbor
  - A record that has similar predictor values to another record.
- Distance Metrics
  - 
