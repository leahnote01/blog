---
title: "Day123 - STAT Review: Regression and Prediction (5)"
layout: single
classes: wide
categories: TIL_25
read_time: True
typora-root-url: ../../
tag: [StatReview, TIL_25]
toc: true 
---

# Practical Statistics for Data Scientists: Regression Diagnostics- Outliers, Heteroskedasticity, and Non-Normality, & Correlated Errors

![84F3DEEE-A960-4570-A946-222FC6BE4EB1_1_105_c](../../images/2025-02-18-TIL25_Day123/84F3DEEE-A960-4570-A946-222FC6BE4EB1_1_105_c.jpeg)

### Regression Diagnostics

> In explanatory modeling, additional steps are taken to assess model fit, mainly through **residuals analysis.** While these steps don't directly address predictive accuracy, <u>they offer valuable insights for predictions.</u> 

#### Key Terms for Regression Diagnostics

- Standardized Residuals
  - Residuals are divided <u>by the standard error of those residuals.</u> 
- **Outliers**
  - Records distant from the data (or the predicted outcome).
- Influential value
  - A value or record that significantly impacts the regression equation. 
- **Leverage**
  - The influence of a single record on a regression equation
  - = hat-value
- Non-normal Residuals
  - Residuals that are <u>not normally distributed</u> may <u>violate certain technical regression criteria</u> but are typically not an issue in data science.
-  **Heteroskedasticity**
  - When certain ranges of the **outcome display residuals with higher variance**, it may suggest that **a predictor is absent from the equation.** 
- Partial Residual Plots
  - A diagnostic plot that illustrates the <u>connection between the **outcome** variable and one **predictor**.</u>
  - = added variables plot<br><br>



#### Outliers

> Typically, an extreme value, commonly called an outlier, <u>is significantly distant from most other observations.</u> Outliers should be considered in **estimates of location** and **variability**, as they can also cause problems in regression models. 

In regression analysis, an outlier is a data point that **significantly deviates from the predicted value.** We detect outliers using <u>the standardized residual, calculated by dividing the residual by its standard error.</u> Standardized residuals represent **how many standard errors** a data point is <u>from the regression line.</u>

<center>
  $\text{Standardized Residual =}\frac{\text{Residual}}{\text{Standard Error of Residuals}}$<br><br>
  $\text{Residual} = y_{actual} - y_{predicted}$ <br><br>
</center>

A common rule of thumb:

- **If a standardized residual is greater than ±3**, the observation is considered a **potential outlier**.
- More conservative thresholds, like **±2.5**, can also be used.



For example, let's utilize a dataset we used in prior postings to fit a regression model to the King County house sales data for all sales in zip code 98105. 

- In R

  ```R
  house_98105 <- house[house$ZipCode == 98105,]
  lm_98105 <- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms
                 + Bedrooms + BldgGrade, data=house_98105)
  ```

- In Python

  ```python
  import statsmodels.api as sm
  import pandas as pd
  
  house_98105 = house.loc[house['ZipCode'] == 98105, ]
  
  predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms',
               'BdgGrade']
  outcome = 'AdjSalePrice'
  
  house_outlier = sm.OLS(house_98105[outcome],
                        house_98105[predictors].assign(const=1))
  result_98105 = house_outlier.fit()
  ```



- In R, we use the `rstandard` function to extract standardized residuals and utilize the `order` function to identify the index of the smallest residual. 

  ```R
  sresid <- rstandard(lm_98105)
  idx <- order(sresid)
  ---
  sresid[idx[1]]
      20429
  -4.326732
  ```

- In Python, we use `statsmodels` and `OLSInfluence` to analyze the residuals.

  ```python
  from statsmodels.stats.outliers_influence import OLSInfluence
  
  influence = OLSInfluence(result_98105)
  sresiduals = influence.resid_studentized_internal # Standardized residuals
  
  # Identify the most extremember negative residual
  outlier_index = sresiduals.idxmin() # get the index of the most extreme outlier
  outlier_value = sresiduals.min() # get the residual value
  
  print(f'Index of most extreme negative residual: {outlier_index}')
  print(f'Standardized residual value: {outlier_value}')
  ```

<br>

- The biggest overestimate from the model is more than four standard errors above the regression line, corresponding to an overestimate of \$757,754. The original data record corresponding to this outlier is as follows in R:

  ```R
  house_98105[idx[1], c('AdjSalePrice', 'SqFtTotLiving', 'SqFtLot',
                'Bathrooms', 'Bedrooms', 'BldgGrade')]
  ---
  AdjSalePrice SqFtTotLiving SqFtLot Bathrooms Bedrooms BldgGrade
           (dbl)         (int)   (int)     (dbl)    (int)     (int)
  20429   119748          2900    7276         3        6         7
  ```

- In Python

  ```python
  outlier = house_98105.loc[sredisuals.idxmin(), :]
  print('AdjSalePrice', outlier[outcome])
  print(outlier[predictors])
  ```



For a **2,900 sq ft house**, a sale price of **\$119,748 is extremely low** for this zip code. Upon further investigation, it turns out that this sale only involved a partial interest in the property (e.g., a legal or financial transaction that does not reflect full ownership). **<u>This is a data issue and should be removed from the analysis.</u>**  <br><Br>













