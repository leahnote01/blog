---
title: "Day175 - MLOps Review: Data Distribution Shifts And Monitoring (2)"
layout: single
classes: wide
categories: TIL_25
read_time: True
typora-root-url: ../
tag: [MLOpsReview, TIL_25]
toc: true 
---

# Designing Machine Learning Systems: Causes of ML System Failures (2) (Correcting Degenerate Feedback Loops) & Data Distribution Shifts 

![BA4320C1-8648-42C6-BED8-2DA53938BA39_1_105_c](../../images/2025-07-05-TIL25_Day174/BA4320C1-8648-42C6-BED8-2DA53938BA39_1_105_c.jpeg)

<br>

*Continuing from the previous posting..* 

##### How to Correct Degenerate Feedback Loops

Because degenerate feedback loops are a common problem, numerous proposed methods exist for correcting them. We’ve discussed that degenerate feedback loops can cause a system’s outputs to be more homogeneous over time. 

Two widely used strategies are:

###### 1. Randomization

**Core idea**: Add randomness to break the loop.

- Show some **random items** to users, even if they aren’t top-ranked.
- Use the feedback from this **exploration traffic** to estimate **true item quality**, not just popularity.
- In recommender systems, instead of only showing users highly ranked items, <u>TikTok shows random items and uses feedback to assess their true quality.</u> New videos get an initial traffic pool to evaluate their unbiased quality, **deciding if they move to a larger pool or are deemed irrelevant.**
  - Every video is given an initial **random traffic pool** (e.g., 100 impressions).
  - Based on early user feedback (likes, watch time), TikTok decides if the video gets promoted to more users.

**Tradeoff**:

- Random recommendations ***can harm user experience, risking user loss.*** An exploration strategy like those in “Contextual bandits as an exploration strategy” boosts item diversity while keeping accuracy. 
  - Schnabel et al. combine **minimal randomness** and **causal inference** <u>to evaluate songs fairly, thereby enhancing the fairness of recommender systems.</u>

<Br>

######  2. Positional Features

Users are more likely to click items shown at the top of the screen. Therefore, if you don’t account for position bias, your model will learn **incorrect patterns**.

We’ve discussed how degenerate feedback loops are caused by biased user feedback on predictions, which depends on **where they are displayed.** For example, <u>in a recommender system where five songs are recommended, the top song is more likely to be clicked.</u> It's unclear whether the model excels at selecting the top song **or if users click more on top recommendations.**

**How to fix this**:

1. During training, **record position as a feature**:

   - e.g., “Is this item shown in position 1?”
   - If the position of a prediction affects its feedback, **encode position using features**. These can be numerical (e.g., 1, 2, 3) or Boolean (e.g., first position or not).

2. Train your model to **learn how position affects clicks**.

3. At inference time, **neutralize** the position bias:

   - Set the “position” feature to False for all predictions.
   - This enables your model to estimate item relevance without considering **position influence**.

4. Then rank the items by these scores and decide final positions.

   - Example Table:

     | ID   | Song      | Position 1 | Click |
     | ---- | --------- | ---------- | ----- |
     | 1    | Shallow   | False      | No    |
     | 2    | Good Vibe | False      | No    |
     | 3    | In Bloom  | True       | Yes   |
     | 4    | Shallow   | True       | Yes   |

     

   - When making predictions, <u><b>the goal is to determine whether a user will click on a song, regardless of its position in the recommendations. </b></u> Set the "1st Position" feature to false, then <u>analyze the model’s predictions for each user to determine the song presentation order.</u>

<br>

###### Advanced Fix: Two-Model Strategy

A more robust approach uses **two models**:

1. **Exposure Model** (with position as a feature):
   - Predicts the probability a user sees/clicks the item given its position
2. **Interest Model** (without position):
   - Predicts **genuine user interest** assuming equal exposure

Final ranking is based on the **interest model**, not the exposure-biased one.

<br>

## Data Distribution Shifts

