---
title: "Day155 - MLOps Review: Introduction to Machine Learning Systems Design (1)"
layout: single
classes: wide
categories: TIL_25
read_time: True
typora-root-url: ../
tag: [StatReview, TIL_25]
toc: true 
---

# Designing Machine Learning Systems: Business and ML Objectives & Requirements for ML Systems

![B65CCA9F-5544-454F-87DB-73820968B8AD_1_105_c](../../images/2025-04-24-TIL25_Day155/B65CCA9F-5544-454F-87DB-73820968B8AD_1_105_c.jpeg)

<br>

## Aligning Business and ML Objectives for Real-World Impact

Machine Learning (ML) promises great potential— but delivering business value through ML remains a challenging endeavor. A common reason ML projects fail to generate meaningful outcomes is a **disconnect between ML objectives and business objectives**. Let's explore how to bridge this gap and build ML systems that are only technically sound but also *business-relevant and production-ready*.

 <br>

### Business vs.ML Objectives: Speaking the Same Language

#### ML Objectives: The Data Scientist's View

When data scienctists work on ML projects, their primary concern often revolves around **model performance metrics** like:

- Accuracy
- Precision / Recall
- F1 Score
- Inference Latency
- AUC-ROC

While these metrics are essential for measuring model behavior, they **do not directly translate into business impact**. Improving model accuracy from 94% to 94.2% may excite an ML team -- but <u>may mean little to a business decision-maker</u> unless it results in tangible value. 

<br>

#### Business Objectives: The Executive View

In contrast, businesses care about metrics like:

- Revenue growth (e.g., through increased conversions or click-through rates)
- Cost reduction (e.g., by reducing manual operations or fraud)
- Customer retention (e.g., reducing churn)
- Engagement (e.g., time spent on that platform)

In essence, businesses aim to **maximize profit** -- either directly through monetization or inderectly via user satisfaction, operational efficiency, or long-term retention.

<br>

#### A Common Pitfall: Misaligned Priorities

A frequent pattern in short-lived ML projects is this:

> The ML team optimizes models for better metrics, <b>but fails to tie those improvements to real-world business KPIs. </b>The business, not seeing value, eventually pulls the plug.

**Example**: A recommender system improves its prediction accruacy by 1%, <u>but unless that leads to higher purchase-through rates, it doesn't justify the engineering investment.</u>

<br>

### Bridging the gap: How to Align Objectives

#### Tie ML Metrics to Business Outcomes

To demonstrate real value, ML teams must **map model improvements to business metrics.** This often involves running **A/B experiments** or **longitudinal studies** that show casual links between:

- A lift in ML accuracy
- A lift in business KPIs (e.g., conversions, revenue, satisfaction)

**Examples of Successful Alignment**:

Some ML use cases natually tie into revenue:

- **Ad click-through rate (CTR)**: A 1% improvement directly increase ad revenue.
- **Fraud detection**: Every prevented fraudulent transaction equals money saved.

Other use cases require intermediary metrics. For instance, Netflix uses a metric called **take-rate** -- the number of "quality plays" devided by the number of reconmmendation shown. Higher take-rate correlates with:

- More total viewing hours
- Lower churn rates

This increases <u>a traceable link from model performance to revenue stability.</u>

But it's not always clear-cut positions. Some ML imparcs are direct to a better personalization engine to make users happier (long term value), but if it also helps them solve problems faster, it might reduce time on the platform. 

In such cases, **experiments** are essential to understand the trade-offs. Business stakeholders don't just want accruacy -- ***they want results***.

<Br>

#### Realism Over Hype

Companies often expect ML to work like magic. *Media hype doesn't help.* While machine learning can bring significant returns, those returns often come **after years of investment** in infrastructure, tooling, and team maturity.

A 2020 Algorithmia survey found that <u>companies using ML for over 5 years deploy models in under 30 days</u>, and newer companies take over a month per deployment. 

> This maturity curve matters. <b>Efficient ML systems pay off- but only if the company has the right processes and tools in place.</b>

<br>

### Requirements: Building ML Systems That Work

Technical excellence isn't enough. Real-world ML systems must also have the requirements as follow explanation.

1. **Reliablity**: They must perform correctly, even when components fail. Unlike traditional software, ML models can **fail silently**-- producing outputs that *look* fine but are completely wrong.
2. **Scalablity**: Systems must handle growths with **more users, larger models, more frequent predictions, and multiple versions of the same model.** (e.g., one per customer) This means building for cloud-native deployment, autoscaling, and model lifecycle management.
3. **Maintainability**: As teams grow and shift, others must be able to *understand past decisions, reproduce results, and update models safely.* That requires **versioned datasets**, clear documentation, and modular pipeplines.
4. **Adaptability**: Data changes, users change, businesses change. Then, ML systems must evolve as well. This involves <u>monitoring data drift, automating retraining, and deploying updates without service interruptions.</u>

<br>

ML projects thrive when they are **grounded in business value** and **engineered with production in mind**. It’s not just about building smart models—it’s about building smart systems that move the needle.

If you're starting a new ML project, <u>ask early:</u>

- *What business metric are we trying to improve?*
- *How will we measure success beyond validation accuracy?*
- *Can we run an experiment to prove value?*

That’s the path to lasting impact.

<br><br>
