---
title: "Day135 - STAT Review: Classification (5)"
layout: single
classes: wide
categories: TIL_25
read_time: True
typora-root-url: ../../
tag: [StatReview, TIL_25]
toc: true 
---

# (Editing) Practical Statistics for Data Scientists: Logistic Regression (3) Logistic vs. Linear Regression, and Assessing the Model

![28E04A53-D6A4-4D46-A59C-AA263434200B_1_105_c](/images/2025-03-07-TIL25_Day135/28E04A53-D6A4-4D46-A59C-AA263434200B_1_105_c.jpeg)

### Logistic vs Linear Regression

| Feature            | Linear Regression                | Logistic Regression                 |
| ------------------ | -------------------------------- | ----------------------------------- |
| Outcome            | Continuous                       | Binary (0 or 1)                     |
| Model Fit          | Least Squares                    | Maximum Likelihood Estimation (MLE) |
| Output             | Continuous prediction (y)        | Probability (between 0 and 1)       |
| Interpretation     | Coefficients = effect on outcome | Coefficients = effect on log-odds   |
| Evaluation Metrics | RMSE, $R^2$                      | Accuracy, Precision, AUC, Log Loss  |

<br>

### How is Logistic Regression Fitted?

##### Maximum Likelihood Estimation (MLE)

Since the response variable is binary, we can't use least squares. Instead, MLE is used:

- MLE tries to **maximize the likelihood** of observing the data given the model.
- It iteratively updates the parameters to **increase the fit**, often using optimization techniques like **Newton-Raphson** or **Fisher Scoring**.
