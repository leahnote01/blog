---
title: "Day62 ML Review - Ensemble Method"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, classifier, ensembleMethod, TIL_24]
toc: true 
---

# Learning with Ensembles

<img src="/blog/images/2024-08-26-TIL24_Day62/E2D2229F-024D-4B3C-8AE4-798A6AE4C781.jpeg"><br><br>

### Key Concepts

> Ensemble methods aim to **combine different classifiers** into a meta-classifier, which can provide better generalization performance than each classifier alone.

For example, assuming that we collected predictions from 10 experts, ensemble methods would allow us to strategically combine those predictions by the ten experts to come up with a prediction that was more accurate and robust than the predictions by each expert. 



Ensemble methods frequently utilize **the majority voting principle**, where the class label that is predicted by the majority of classifiers is selected, signifying that <u>it has received over 50 percent of the votes.</u> This approach can be expanded to handle multiclass scenarios through plurality voting, in which the class label that garners the highest number of votes (the mode) is chosen.

Ensembles can be constructed using <u>various classification algorithms</u>. For instance, decision trees, support vector machines, logistic regression classifiers, and others can be used depending on the technique. Alternatively, the same base classification algorithm can be employed to fit different subsets of the training dataset. A well-known example of this approach is **the random forest** algorithm, <u>which combines multiple decision tree classifiers.</u>



<center>
  <img src="/blog/images/2024-08-26-TIL24_Day62/image-20240910132901551.png" width="70%">
  <I><font size="3pt">Image from (https://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/)</font></I>
</center>



The `EnsembleVoteClassifier` implements "hard" and "soft" voting. In hard voting, we predict the final class label as the class label that has been predicted most frequently by the classification models. In soft voting, we predict the class labels by averaging the class probabilities (only recommended if the classifiers are well-calibrated).

<br>

### Mathematics

To predict a class 
