---
title: "Day24 Statistics Review (3)"
layout: single
classes: wide
categories: TIL_24
typora-root-url: ../
tag: [mlReview, statstics, statReview, TIL_24]
toc: true 
---

# Test Statistics (Z-Test, t-Test, and Chi-Squared Test)

<img src="/blog/images/2024-06-19-TIL24_Day24/B9FF5BF4-EA91-4D12-ADC8-2A63E6A7371E.jpeg">

<br><br>

*(Ace the Data Science Interview: 201 Real Interview Questions Asked By FAANG, Tech Startups, & Wall Street)*

### Hypothesis Testing

> It's important to understand that hypothesis testing forms the foundation of A/B testing. Essentially, in A/B testing, different versions of a feature are presented to various users in a sample, and each variant is evaluated to see if there was an improvement in the key engagement metrics.

#### Example of Hypothesis Testing

<I>(https://www.investopedia.com/terms/h/hypothesistesting.asp)</I>

If an individual wants to determine whether a penny has a 50% chance of landing on heads, they would set up a statistical test. The null hypothesis in this case would be that the probability of landing on heads is 50%, represented as $H_0 : P = 0.5$. The alternative hypothesis ($H_1$) would be that the probability is not 50%, indicated by striking through the equal sign in the null hypothesis.

A random sample of 100 coin flips is taken to conduct the test. If the sample yields 40 heads and 60 tails, the analyst would reject the null hypothesis in favor of the alternative hypothesis, concluding that a penny does not have a 50% chance of landing on heads.

However, if the sample shows 48 heads and 52 tails, it could still be consistent with a fair coin. In this case, where the null hypothesis is "accepted," the analyst would attribute the difference between the expected and observed results to chance alone.

<br><Br>

#### Test Statistics

A test statistic is a numerical summary used to <u>determine whether the null or alternative hypothesis should be accepted as correct</u>. Specifically, it assumes that the parameter of interest follows a particular sampling distribution under the null hypothesis.

For instance, the number of heads in a series of coin flips may follow a binomial distribution. However, with a sufficiently large sample size, <u>the sampling distribution should be approximately normally distributed</u>. Therefore, the sampling distribution for the total number of heads **in a large series** of coin flips would be considered normally distributed.

Here are several variations in test statistics and their distributions:

1. Z-test: This assumes that the test statistic follows a normal distribution under the null hypothesis.
2. t-test: This uses a student's t-distribution instead of a normal distribution.
3. Chi-squared test: This is used to assess goodness of fit and to check whether two categorical variables are independent.

<Br>

#### Z-Test

Typically, the Z-test is utilized when dealing with a **large sample size** to invoke the Central Limit Theorem or when the **population variance is known**. On the other hand, *a t-test is used with a small sample size or when the population variance is unknown.* The Z-test for a population mean is formulated as follows in the case where the population variance ($\sigma^2$) is known. 

<center>
  $z = \frac{\bar{x} - \mu_0}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)$<br>
</center>

<br>

#### t-Test

The t-test is similar to the Z-test, but it uses *the sample variance* $s^2$ instead of the population variance. The t-test is determined <u>by the degrees of freedom</u>, which represent the number of independent observations in a dataset and are denoted by $n-1$.

<center>
  $t=\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}}\sim t_{n-1}$ <br>
  where $s^2 = \frac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}$ <br><br>
</center>

As mentioned before, the t-distribution resembles the normal distribution but **has larger tails**, meaning **extreme events occur more frequently** than expected by the modeled distribution. This phenomenon is common, particularly in economics and Earth science.

<br>

#### Chi-Squared Test

The Chi-squared test statistic is utilized to evaluate **goodness of fit** and is calculated in the following.

<center>
  $\chi^2 = \sum_i\frac{(O_i-E_i)^2}{E_i}$<br><br>
</center>

where $O_i$ is the observed value and $E_i$ is the expected value. The degrees of freedom for the chi-squared test statistic depends on the <u>number of categories in the distribution.</u>

<u>To determine if two categorical variables are independent, we can use a chi-squared test.</u> Start by creating a **contingency table** with one variable's values as rows and the other variable's values as columns, then look for intersections in the table. This test uses the same chi-squared test statistic as mentioned above.

<br>

#### Hypothesis Testing for Population Proportions

The Central Limit Theorem (CLT) allows us to apply the Z-test to random variables of any distribution. <br><br>
*(For instance, when we want to estimate the sample proportion of a population with a specific characteristic, we can consider the population members as Bernoulli random variables, where those with the characteristic are represented by "1s" and those without it are represented by "0s". We can then calculate the sample proportion by dividing the sum of these Bernoulli random variables by the total population size.)* <br><br>From there, we can compute the sample mean and variance of the overall proportion and form the hypotheses accordingly.

<center>
  $H_0: \hat{p}=p_0$ <br>
  $H_1: \hat{p} \neq p_0$ <br><br>
</center>

and the corresponding test statistic to conduct a Z-test would be:

<center>
  $z= \frac{\hat{p}-p_0}{\frac{p_0(1-p_0)}{n}}$ <br><br>
</center>

In practice, these test statistics form the core of A/B testing. 

For instance, consider the previously discussed case, in which we seek to measure conversion rates within groups A and B, where A is the control group, and B has the special treatment (in this case, a marketing campaign). Adopting the same null hypothesis as before, we can use a Z-test to assess the difference in empirical population means (in this case, conversion rates) and test its statistical significance at a predetermined level.

When asked about A/B testing or related topics, we should always cite the relevant test statistic and the cause of its validity (usually the CLT). 



#### p-values and Confidence Intervals



<br><br>

